{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY-YFJUIuSlL",
    "outputId": "759077ac-5617-437e-978c-b6f58afbcc3e"
   },
   "outputs": [],
   "source": [
    "# Not all of these are needed, but most are (this cell is an artefact of a previous analysis). \n",
    "# If you don't have some of these python libraries, the easiest way to install them is using\n",
    "# \n",
    "# > pip install library_name\n",
    "# \n",
    "# Alternatively, you can do so using Anaconda, using \n",
    "# \n",
    "# > conda install library_name\n",
    "\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "# stdout = sys.stdout\n",
    "# sys.reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')\n",
    "# sys.stdout = stdout\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# import jupyternotify\n",
    "# ip = get_ipython()\n",
    "# ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/iblinderman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/iblinderman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cq9Nby2EuSlV",
    "outputId": "d37ee235-d361-45d9-bc7c-edb10cb68df5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandwich cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black-and-white cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>popular cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mountain: prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sweet sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creme-filled cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nabisco cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cookie favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mountain: comb form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>layered cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>black-and-white treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>two-tone treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>two-tone cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hydrox rival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>triple-decker cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>black-and-white cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nabisco treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cream-filled cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>twistable cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>best-selling cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sandwich cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>twistable treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>black-and-white snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cookie since 1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>creme cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cookie brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lunchbox treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dunkable treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>three-layer cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>classic cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>crunchy treats with milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>cookie choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>cookies in a box lunch, sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>some black-and-white snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>twisted-apart cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>twistable snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>wonderfilled cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>cookies deep-fried at fairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>cookies in mcflurrys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>black-and-white sleeveful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>dunkables since 1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>black-white-black snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>cookies in sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>cream-filled chocolate snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>sandwich snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>double stufs, eg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>droxies lookalikes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>stackable snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>ornately embossed edibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>ingredients in tgi friday's dessert cup of dirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>popular snacks that inspired this puzzle's theme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>lunchbox favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>crunchy pie crust components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>sandwiches in lunchboxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>sweet snacks for over a century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>makeup of some pie crusts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>tripartite treats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>crumbles on sundaes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>treats once advertised as \"the original twister\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>three-part snacks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  clue\n",
       "0                                      sandwich cookie\n",
       "1                               black-and-white cookie\n",
       "2                                       popular cookie\n",
       "3                                     mountain: prefix\n",
       "4                                       sweet sandwich\n",
       "...                                                ...\n",
       "1298                         makeup of some pie crusts\n",
       "1299                                 tripartite treats\n",
       "1300                               crumbles on sundaes\n",
       "1301  treats once advertised as \"the original twister\"\n",
       "1302                                 three-part snacks\n",
       "\n",
       "[1303 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and cleaning the data structure. For this example, I'm using StackOverflow posts; specifically, \n",
    "# posts to the \"Interpersonal questions\" site on StackExchange. There's a bit of cleaning that's necessary here, \n",
    "# Which I take care of in this cell.\n",
    "\n",
    "df_stack = pd.read_csv(\"oreo-clues.tsv\", sep='\\t')\n",
    "df_stack\n",
    "# df_stack_qs = df_stack[df_stack['PostTypeId']==1]\n",
    "# from HTMLParser import HTMLParser\n",
    "\n",
    "# class MLStripper(HTMLParser):\n",
    "#     def __init__(self):\n",
    "#         self.reset()\n",
    "#         self.fed = []\n",
    "#     def handle_data(self, d):\n",
    "#         self.fed.append(d)\n",
    "#     def get_data(self):\n",
    "#         return ''.join(self.fed)\n",
    "\n",
    "# def strip_tags(html):\n",
    "#     s = MLStripper()\n",
    "#     s.feed(html)\n",
    "#     return s.get_data()\n",
    "\n",
    "# df_stack_qs = df_stack_qs.replace(r'\\n','', regex=True) \n",
    "\n",
    "# df_stack_qs['Body']=  df_stack_qs['Body'].apply(lambda x: strip_tags(x)) \n",
    "\n",
    "# Here's what the end product looks like\n",
    "# df_stack_qs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4F7P3KapuSlb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sandwich cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>black-and-white cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>popular cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mountain: prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sweet sandwich</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title                question\n",
       "0      0         sandwich cookie\n",
       "1      1  black-and-white cookie\n",
       "2      2          popular cookie\n",
       "3      3        mountain: prefix\n",
       "4      4          sweet sandwich"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack = df_stack.reset_index()\n",
    "df_stack.columns = ['title','question']\n",
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjucVqbouSld"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1056</td>\n",
       "      <td>cookie that some people eat with mustard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                  question\n",
       "1056   1056  cookie that some people eat with mustard"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack[df_stack['question'].str.contains('musta')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22RZNM-auSlg"
   },
   "outputs": [],
   "source": [
    "# Creating lists of questions + their relevant titles\n",
    "questions =  df_stack['question'].tolist()\n",
    "titles =  df_stack['title'].tolist()\n",
    "\n",
    "\n",
    "# Adding title and data to a dictionary\n",
    "tempDict = {}\n",
    "for title, question in zip(titles, questions):\n",
    "    tempDict[title]=question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSqrijYSuSlj",
    "outputId": "ae18e971-b2c8-463d-96ea-04b8170cda98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating tf-idf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducing tf-idf to dimensions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Removing punctuation from the text, as well as some misc. irrelevant characters \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower() # lower case\n",
    "    for e in set(string.punctuation+'\\n'+'\\t'): # remove punctuation and line breaks/tabs\n",
    "        text = text.replace(e, ' ')\t\n",
    "    for i in range(0,10):\t# remove double spaces\n",
    "        text = text.replace('  ', ' ')\n",
    "    text = text.translate(string.punctuation)  # punctuation\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = [w for w in tokens if not w in stopwords.words('english')] # stopwords\n",
    "    stems = []\n",
    "    for item in tokens: # stem\n",
    "        stems.append(wordnet_lemmatizer.lemmatize(item))\n",
    "    return stems\n",
    "\n",
    "# calculate tfidf \n",
    "print(\"calculating tf-idf\")\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', min_df=0.025, max_df=.5) #NOTE\n",
    "# this step takes longest & contains lots of important parameters; playing with these and experimenting\n",
    "# with them is recommended. Starting here::\n",
    "# https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments\n",
    "# and moving on to the official docs here:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "# is a good idea.\n",
    "\n",
    "tfs = tfidf.fit_transform(tempDict.values())\n",
    "print(\"reducing tf-idf to dimensions\")\n",
    "tfs_reduced = TruncatedSVD(n_components=10, random_state=0).fit_transform(tfs)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmGISjzkuSlo",
    "outputId": "f0b436ca-c604-4022-c07e-8b1933270ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1303\n",
      "[t-SNE] Computed conditional probabilities for sample 1303 / 1303\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] Iteration 50: error = 46.8079256, gradient norm = 0.0413921 (50 iterations in 5.927s)\n",
      "[t-SNE] Iteration 100: error = 43.3915136, gradient norm = 0.0066409 (50 iterations in 5.400s)\n",
      "[t-SNE] Iteration 150: error = 43.6301050, gradient norm = 0.0143428 (50 iterations in 5.877s)\n",
      "[t-SNE] Iteration 200: error = 43.6371546, gradient norm = 0.0061388 (50 iterations in 9.583s)\n",
      "[t-SNE] Iteration 250: error = 43.4846728, gradient norm = 0.0048782 (50 iterations in 5.662s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 43.484673\n",
      "[t-SNE] Iteration 300: error = 4.4242262, gradient norm = 0.0003310 (50 iterations in 5.385s)\n",
      "[t-SNE] Iteration 350: error = 4.0997117, gradient norm = 0.0000417 (50 iterations in 6.203s)\n",
      "[t-SNE] Iteration 400: error = 3.9377756, gradient norm = 0.0000182 (50 iterations in 5.773s)\n",
      "[t-SNE] Iteration 450: error = 3.8353034, gradient norm = 0.0000112 (50 iterations in 5.496s)\n",
      "[t-SNE] Iteration 500: error = 3.7628391, gradient norm = 0.0000072 (50 iterations in 5.644s)\n",
      "[t-SNE] Iteration 550: error = 3.7113195, gradient norm = 0.0000048 (50 iterations in 6.096s)\n",
      "[t-SNE] Iteration 600: error = 3.6719341, gradient norm = 0.0000036 (50 iterations in 5.432s)\n",
      "[t-SNE] Iteration 650: error = 3.6389478, gradient norm = 0.0000028 (50 iterations in 5.510s)\n",
      "[t-SNE] Iteration 700: error = 3.6103145, gradient norm = 0.0000022 (50 iterations in 5.646s)\n",
      "[t-SNE] Iteration 750: error = 3.5860487, gradient norm = 0.0000019 (50 iterations in 5.464s)\n",
      "[t-SNE] Iteration 800: error = 3.5646216, gradient norm = 0.0000016 (50 iterations in 5.571s)\n",
      "[t-SNE] Iteration 850: error = 3.5459948, gradient norm = 0.0000013 (50 iterations in 5.489s)\n",
      "[t-SNE] Iteration 900: error = 3.5296698, gradient norm = 0.0000011 (50 iterations in 5.370s)\n",
      "[t-SNE] Iteration 950: error = 3.5145789, gradient norm = 0.0000010 (50 iterations in 5.967s)\n",
      "[t-SNE] Iteration 1000: error = 3.5006237, gradient norm = 0.0000009 (50 iterations in 6.021s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.500624\n"
     ]
    }
   ],
   "source": [
    "model = TSNE(n_components=10, perplexity=10, verbose=2, method='exact').fit_transform(tfs_reduced)\n",
    "\n",
    "# save to json file\n",
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "x_norm = (x_axis-np.min(x_axis)) / (np.max(x_axis) - np.min(x_axis))\n",
    "y_norm = (y_axis-np.min(y_axis)) / (np.max(y_axis) - np.min(y_axis))\n",
    "data = {\"x\":x_norm.tolist(), \"y\":y_norm.tolist(), \"names\":tempDict.keys()} #output x and y coords in data\n",
    "with open('test.json', 'w') as outfile:\n",
    "    json.dump(list(data), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ni6mVt8ouSlr"
   },
   "outputs": [],
   "source": [
    "# Importing json of results, merging it with the original file, and outputting a CSV which will contain\n",
    "# the X and Y coords of each point, which we'll use to create our tSNE plot\n",
    "df_xyplot = pd.read_json(\"test.json\")\n",
    "\n",
    "\n",
    "\n",
    "test_df_coords = pd.DataFrame(data)[['x','y']].reset_index()\n",
    "test_df_coords.columns = ['names','x','y']\n",
    "\n",
    "result = pd.merge(df_stack, test_df_coords, left_on='title', right_on='names')\n",
    "result.to_csv(\"oreos_tsn_v3_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqxPq7xguSlu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>names</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      x\n",
       "1      y\n",
       "2  names"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "df_xyplot = pd.read_json(\"test.json\")\n",
    "df_xyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>names</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sandwich cookie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579764</td>\n",
       "      <td>1.456600e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>black-and-white cookie</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248767</td>\n",
       "      <td>2.973879e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>popular cookie</td>\n",
       "      <td>2</td>\n",
       "      <td>0.779867</td>\n",
       "      <td>9.100980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mountain: prefix</td>\n",
       "      <td>3</td>\n",
       "      <td>0.520758</td>\n",
       "      <td>2.977358e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sweet sandwich</td>\n",
       "      <td>4</td>\n",
       "      <td>0.566940</td>\n",
       "      <td>1.309917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>creme-filled cookie</td>\n",
       "      <td>5</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>4.255381e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>nabisco cookie</td>\n",
       "      <td>6</td>\n",
       "      <td>0.659073</td>\n",
       "      <td>2.865407e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>cookie favorite</td>\n",
       "      <td>7</td>\n",
       "      <td>0.652972</td>\n",
       "      <td>9.571073e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>mountain: comb form</td>\n",
       "      <td>8</td>\n",
       "      <td>0.410280</td>\n",
       "      <td>2.848355e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>layered cookie</td>\n",
       "      <td>9</td>\n",
       "      <td>0.754130</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>black-and-white treat</td>\n",
       "      <td>10</td>\n",
       "      <td>0.248178</td>\n",
       "      <td>3.090401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>two-tone treat</td>\n",
       "      <td>11</td>\n",
       "      <td>0.987715</td>\n",
       "      <td>1.866979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>two-tone cookie</td>\n",
       "      <td>12</td>\n",
       "      <td>0.707644</td>\n",
       "      <td>9.202199e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>hydrox rival</td>\n",
       "      <td>13</td>\n",
       "      <td>0.430001</td>\n",
       "      <td>2.942690e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>triple-decker cookie</td>\n",
       "      <td>14</td>\n",
       "      <td>0.697457</td>\n",
       "      <td>9.674395e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>black-and-white cookies</td>\n",
       "      <td>15</td>\n",
       "      <td>0.235149</td>\n",
       "      <td>2.936868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>nabisco treat</td>\n",
       "      <td>16</td>\n",
       "      <td>0.693520</td>\n",
       "      <td>2.852128e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>cream-filled cookie</td>\n",
       "      <td>17</td>\n",
       "      <td>0.320651</td>\n",
       "      <td>1.634191e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>twistable cookie</td>\n",
       "      <td>18</td>\n",
       "      <td>0.688398</td>\n",
       "      <td>9.397627e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>best-selling cookie</td>\n",
       "      <td>19</td>\n",
       "      <td>0.691543</td>\n",
       "      <td>9.600074e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>sandwich cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>1.103679e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>twistable treat</td>\n",
       "      <td>21</td>\n",
       "      <td>0.994254</td>\n",
       "      <td>1.837558e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>black-and-white snack</td>\n",
       "      <td>22</td>\n",
       "      <td>0.225222</td>\n",
       "      <td>3.107769e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>cookie since 1912</td>\n",
       "      <td>23</td>\n",
       "      <td>0.634432</td>\n",
       "      <td>4.236034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>creme cookie</td>\n",
       "      <td>24</td>\n",
       "      <td>0.632454</td>\n",
       "      <td>4.255382e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>cookie brand</td>\n",
       "      <td>25</td>\n",
       "      <td>0.339114</td>\n",
       "      <td>4.563479e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>lunchbox treat</td>\n",
       "      <td>26</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>1.929740e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>dunkable treat</td>\n",
       "      <td>27</td>\n",
       "      <td>0.998429</td>\n",
       "      <td>1.929371e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>three-layer cookie</td>\n",
       "      <td>28</td>\n",
       "      <td>0.724368</td>\n",
       "      <td>9.625579e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>classic cookie</td>\n",
       "      <td>29</td>\n",
       "      <td>0.707682</td>\n",
       "      <td>9.378130e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1273</td>\n",
       "      <td>crunchy treats with milk</td>\n",
       "      <td>1273</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>2.093164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1274</td>\n",
       "      <td>cookie choices</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.760199</td>\n",
       "      <td>9.482309e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1275</td>\n",
       "      <td>cookies in a box lunch, sometimes</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.297220</td>\n",
       "      <td>4.471696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1276</td>\n",
       "      <td>some black-and-white snacks</td>\n",
       "      <td>1276</td>\n",
       "      <td>0.225222</td>\n",
       "      <td>3.107779e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>twisted-apart cookies</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.317227</td>\n",
       "      <td>1.935919e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>1278</td>\n",
       "      <td>twistable snacks</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>4.478728e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1279</td>\n",
       "      <td>wonderfilled cookies</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.291788</td>\n",
       "      <td>4.462508e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1280</td>\n",
       "      <td>cookies deep-fried at fairs</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.297220</td>\n",
       "      <td>4.471696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1281</td>\n",
       "      <td>cookies in mcflurrys</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.297220</td>\n",
       "      <td>4.471696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1282</td>\n",
       "      <td>black-and-white sleeveful</td>\n",
       "      <td>1282</td>\n",
       "      <td>0.240511</td>\n",
       "      <td>3.026696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1283</td>\n",
       "      <td>dunkables since 1912</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.373906</td>\n",
       "      <td>3.196797e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1284</td>\n",
       "      <td>black-white-black snacks</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.231226</td>\n",
       "      <td>3.075357e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1285</td>\n",
       "      <td>cookies in sleeves</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.291787</td>\n",
       "      <td>4.461208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>cream-filled chocolate snacks</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.280484</td>\n",
       "      <td>1.844926e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1287</td>\n",
       "      <td>sandwich snacks</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>1.064753e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1288</td>\n",
       "      <td>double stufs, eg</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.436249</td>\n",
       "      <td>3.035610e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1289</td>\n",
       "      <td>droxies lookalikes</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.479739</td>\n",
       "      <td>3.224419e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>stackable snacks</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>4.551259e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>ornately embossed edibles</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.458478</td>\n",
       "      <td>3.002247e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>ingredients in tgi friday's dessert cup of dirt</td>\n",
       "      <td>1292</td>\n",
       "      <td>0.493675</td>\n",
       "      <td>4.837035e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>popular snacks that inspired this puzzle's theme</td>\n",
       "      <td>1293</td>\n",
       "      <td>0.454769</td>\n",
       "      <td>4.821799e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>lunchbox favorites</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.473422</td>\n",
       "      <td>3.256500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>crunchy pie crust components</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.481606</td>\n",
       "      <td>2.912151e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>sandwiches in lunchboxes</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.566940</td>\n",
       "      <td>1.309917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1297</td>\n",
       "      <td>sweet snacks for over a century</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>4.477430e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>makeup of some pie crusts</td>\n",
       "      <td>1298</td>\n",
       "      <td>0.489215</td>\n",
       "      <td>3.055818e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1299</td>\n",
       "      <td>tripartite treats</td>\n",
       "      <td>1299</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.942446e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>crumbles on sundaes</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.471657</td>\n",
       "      <td>3.263242e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1301</td>\n",
       "      <td>treats once advertised as \"the original twister\"</td>\n",
       "      <td>1301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.883303e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1302</td>\n",
       "      <td>three-part snacks</td>\n",
       "      <td>1302</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>4.463539e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                          question  names  \\\n",
       "0         0                                   sandwich cookie      0   \n",
       "1         1                            black-and-white cookie      1   \n",
       "2         2                                    popular cookie      2   \n",
       "3         3                                  mountain: prefix      3   \n",
       "4         4                                    sweet sandwich      4   \n",
       "...     ...                                               ...    ...   \n",
       "1298   1298                         makeup of some pie crusts   1298   \n",
       "1299   1299                                 tripartite treats   1299   \n",
       "1300   1300                               crumbles on sundaes   1300   \n",
       "1301   1301  treats once advertised as \"the original twister\"   1301   \n",
       "1302   1302                                 three-part snacks   1302   \n",
       "\n",
       "             x         y  \n",
       "0     0.579764  0.145660  \n",
       "1     0.248767  0.297388  \n",
       "2     0.779867  0.910098  \n",
       "3     0.520758  0.297736  \n",
       "4     0.566940  0.130992  \n",
       "...        ...       ...  \n",
       "1298  0.489215  0.305582  \n",
       "1299  0.992173  0.194245  \n",
       "1300  0.471657  0.326324  \n",
       "1301  1.000000  0.188330  \n",
       "1302  0.015115  0.446354  \n",
       "\n",
       "[1303 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"x\":x_norm.tolist(), \"y\":y_norm.tolist(), \"names\":tempDict.keys()}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "t-SNE for Thomas.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
