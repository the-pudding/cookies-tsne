{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY-YFJUIuSlL",
    "outputId": "759077ac-5617-437e-978c-b6f58afbcc3e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Not all of these are needed, but most are (this cell is an artefact of a previous analysis). \n",
    "# If you don't have some of these python libraries, the easiest way to install them is using\n",
    "# \n",
    "# > pip install library_name\n",
    "# \n",
    "# Alternatively, you can do so using Anaconda, using \n",
    "# \n",
    "# > conda install library_name\n",
    "\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cq9Nby2EuSlV",
    "outputId": "d37ee235-d361-45d9-bc7c-edb10cb68df5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16538</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to approach a narcissist parent about thei...</td>\n",
       "      <td>TL;DR: My dad is calling my sister an embarras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16545</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roommate Upset I Woke Him Up</td>\n",
       "      <td>I encountered a strange situation with my room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16547</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grandpa has dementia, how to include him in co...</td>\n",
       "      <td>I'm not sure if this is a question that can be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16556</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to Tell Family Dr I am Content Helping My ...</td>\n",
       "      <td>This has been bothering me for sometime now.My...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16560</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How/whether to let people know I don't like re...</td>\n",
       "      <td>My husband and I have never liked cut flowers,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  PostTypeId  ParentId  \\\n",
       "1   16538           1       NaN   \n",
       "5   16545           1       NaN   \n",
       "7   16547           1       NaN   \n",
       "12  16556           1       NaN   \n",
       "16  16560           1       NaN   \n",
       "\n",
       "                                                Title  \\\n",
       "1   How to approach a narcissist parent about thei...   \n",
       "5                        Roommate Upset I Woke Him Up   \n",
       "7   Grandpa has dementia, how to include him in co...   \n",
       "12  How to Tell Family Dr I am Content Helping My ...   \n",
       "16  How/whether to let people know I don't like re...   \n",
       "\n",
       "                                                 Body  \n",
       "1   TL;DR: My dad is calling my sister an embarras...  \n",
       "5   I encountered a strange situation with my room...  \n",
       "7   I'm not sure if this is a question that can be...  \n",
       "12  This has been bothering me for sometime now.My...  \n",
       "16  My husband and I have never liked cut flowers,...  "
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and cleaning the data structure. For this example, I'm using StackOverflow posts; specifically, \n",
    "# posts to the \"Interpersonal questions\" site on StackExchange. There's a bit of cleaning that's necessary here, \n",
    "# Which I take care of in this cell.\n",
    "\n",
    "df_stack = pd.read_csv(\"QueryResults.csv\")\n",
    "df_stack_qs = df_stack[df_stack['PostTypeId']==1]\n",
    "from HTMLParser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "df_stack_qs = df_stack_qs.replace(r'\\n','', regex=True) \n",
    "\n",
    "df_stack_qs['Body']=  df_stack_qs['Body'].apply(lambda x: strip_tags(x)) \n",
    "\n",
    "# Here's what the end product looks like\n",
    "df_stack_qs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4F7P3KapuSlb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjucVqbouSld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22RZNM-auSlg"
   },
   "outputs": [],
   "source": [
    "# Creating lists of questions + their relevant titles\n",
    "questions =  df_stack_qs['Body'].tolist()\n",
    "titles =  df_stack_qs['Title'].tolist()\n",
    "\n",
    "\n",
    "# Adding title and data to a dictionary\n",
    "tempDict = {}\n",
    "for title, question in zip(titles, questions):\n",
    "    tempDict[title]=question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSqrijYSuSlj",
    "outputId": "ae18e971-b2c8-463d-96ea-04b8170cda98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating tf-idf\n",
      "reducing tf-idf to dimensions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Removing punctuation from the text, as well as some misc. irrelevant characters \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower() # lower case\n",
    "    for e in set(string.punctuation+'\\n'+'\\t'): # remove punctuation and line breaks/tabs\n",
    "        text = text.replace(e, ' ')\t\n",
    "    for i in range(0,10):\t# remove double spaces\n",
    "        text = text.replace('  ', ' ')\n",
    "    text = text.translate(string.punctuation)  # punctuation\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = [w for w in tokens if not w in stopwords.words('english')] # stopwords\n",
    "    stems = []\n",
    "    for item in tokens: # stem\n",
    "        stems.append(wordnet_lemmatizer.lemmatize(item))\n",
    "    return stems\n",
    "\n",
    "# calculate tfidf \n",
    "print \"calculating tf-idf\"\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', min_df=0.025, max_df=.5) #NOTE\n",
    "# this step takes longest & contains lots of important parameters; playing with these and experimenting\n",
    "# with them is recommended. Starting here::\n",
    "# https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments\n",
    "# and moving on to the official docs here:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "# is a good idea.\n",
    "\n",
    "tfs = tfidf.fit_transform(tempDict.values())\n",
    "print \"reducing tf-idf to dimensions\"\n",
    "tfs_reduced = TruncatedSVD(n_components=100, random_state=0).fit_transform(tfs)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmGISjzkuSlo",
    "outputId": "f0b436ca-c604-4022-c07e-8b1933270ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2619\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2619\n",
      "[t-SNE] Computed conditional probabilities for sample 2619 / 2619\n",
      "[t-SNE] Mean sigma: 0.203230\n",
      "[t-SNE] Iteration 25: error = 19.8171082, gradient norm = 0.0783719\n",
      "[t-SNE] Iteration 50: error = 20.6833585, gradient norm = 0.0641763\n",
      "[t-SNE] Iteration 75: error = 21.0182451, gradient norm = 0.0662294\n",
      "[t-SNE] Iteration 100: error = 20.7684213, gradient norm = 0.0635221\n",
      "[t-SNE] Error after 100 iterations with early exaggeration: 20.768421\n",
      "[t-SNE] Iteration 125: error = 1.9375553, gradient norm = 0.0038172\n",
      "[t-SNE] Iteration 150: error = 1.8434535, gradient norm = 0.0032058\n",
      "[t-SNE] Iteration 175: error = 1.8383726, gradient norm = 0.0041525\n",
      "[t-SNE] Iteration 200: error = 1.8414299, gradient norm = 0.0035076\n",
      "[t-SNE] Iteration 225: error = 1.8365453, gradient norm = 0.0040166\n",
      "[t-SNE] Iteration 250: error = 1.8425447, gradient norm = 0.0046922\n",
      "[t-SNE] Iteration 275: error = 1.8668061, gradient norm = 0.0049425\n",
      "[t-SNE] Iteration 300: error = 1.8801819, gradient norm = 0.0046985\n",
      "[t-SNE] Iteration 300: did not make any progress during the last 50 episodes. Finished.\n",
      "[t-SNE] Error after 300 iterations: 1.880182\n"
     ]
    }
   ],
   "source": [
    "model = TSNE(n_components=2, perplexity=100, verbose=2, method='exact').fit_transform(tfs_reduced)\n",
    "\n",
    "# save to json file\n",
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "x_norm = (x_axis-np.min(x_axis)) / (np.max(x_axis) - np.min(x_axis))\n",
    "y_norm = (y_axis-np.min(y_axis)) / (np.max(y_axis) - np.min(y_axis))\n",
    "data = {\"x\":x_norm.tolist(), \"y\":y_norm.tolist(), \"names\":tempDict.keys()} #output x and y coords in data\n",
    "with open('test.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ni6mVt8ouSlr"
   },
   "outputs": [],
   "source": [
    "# Importing json of results, merging it with the original file, and outputting a CSV which will contain\n",
    "# the X and Y coords of each point, which we'll use to create our tSNE plot\n",
    "df_xyplot = pd.read_json(\"test.json\")\n",
    "result = pd.merge(df_stack_qs, df_xyplot, left_on='Title', right_on='names')\n",
    "result.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqxPq7xguSlu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "t-SNE for Thomas.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
